{"cells":[{"cell_type":"markdown","metadata":{"id":"7jSCEADURSkn"},"source":["# Segmentation: U-Net and MS-D\n","\n","In this notebook, we build two different models for binary segmentation of histological images. \n","\n","We use the [Warwick QU gland segmentation](https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/) (GlaS) data set consisting of H&E stained histological images from the GlaS@MICCAI 2015 competition. "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"az5V38p0RSks","executionInfo":{"status":"ok","timestamp":1657241192545,"user_tz":-330,"elapsed":6,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}}},"outputs":[],"source":["# URL of Warwick QU GlaS data set.\n","# will be downloaded and extracted to ~/.keras if not existent\n","URL = 'https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip'\n","\n","# size of images for prediction\n","HEIGHT, WIDTH = 320, 448\n","\n","# size of image patches for training \n","## note: must be divisible by 32 for UNet \n","PATCH_HEIGHT, PATCH_WIDTH = 128,128"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kXTvIxz6RSkt","executionInfo":{"status":"ok","timestamp":1657241199448,"user_tz":-330,"elapsed":494,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}}},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pylab as plt\n","import numpy as np\n","import pandas as pd\n","import os, glob, sys"]},{"cell_type":"markdown","metadata":{"id":"SJn5V35qRSku"},"source":["# Utility functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"r1eRslKBRSku","executionInfo":{"status":"ok","timestamp":1657241202771,"user_tz":-330,"elapsed":521,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}}},"outputs":[],"source":["def sort_human(strings):\n","    def atoi(text):\n","        return int(text) if text.isdigit() else text\n","    \n","    def human_keys(text):\n","        import re\n","        return [ atoi(c) for c in re.split('(\\d+)', text) ]\n","    \n","    strings.sort(key=human_keys)\n","    return strings\n","\n","def import_image(filename, scale=True, expand=None, verbose=True):\n","    \"\"\"\n","    Read an image file.\n","\n","    Args:\n","        filename (str): a file name (path)\n","        scale (bool): should the returned image be scaled to float32 [0,1]\n","        expand (int): expands the specified axis of the image (for keras with channels last this should be -1)\n","        verbose (bool): print information about the image\n","\n","    Returns:\n","        (numpy.array) returns an numpy array containing the image\n","    \"\"\"\n","    from skimage.io import imread, imsave\n","\n","    if(filename.endswith('.tif')):\n","        image=imread(filename, plugin='tifffile')\n","    else:\n","        image=imread(filename)\n","    if scale:\n","        if image.dtype==np.bool:\n","            image=image.astype('float32')\n","        elif image.dtype==np.int8:\n","            image=(image.astype('float32')+(2**8/2))/(2**8-1)\n","        elif image.dtype==np.int16:\n","            image=(image.astype('float32')+(2**16/2))/(2**16-1)\n","        elif image.dtype==np.uint8:\n","            image=image.astype('float32')/(2**8-1)\n","        elif image.dtype==np.uint16:\n","            image=image.astype('float32')/(2**16-1)\n","        else:\n","            warnings.warn('Scaling for dtype {} is not yet implemented!'.format(image.dtype))\n","    if expand!=None:\n","        image=np.expand_dims(image,axis=expand)\n","    if verbose:\n","        image_info(image)\n","    return image\n","\n","def draw_model(model):\n","    try: \n","        import graphviz\n","        from IPython.display import display,SVG\n","        from keras.utils.vis_utils import model_to_dot\n","        return SVG(model_to_dot(model, show_shapes=False, show_layer_names=False, rankdir='LR').create(prog='dot', format='svg'))\n","    except:\n","        raise ImportError('Graphviz not installed.')"]},{"cell_type":"markdown","metadata":{"id":"oqDvtcdrRSkv"},"source":["# Get data"]},{"cell_type":"markdown","metadata":{"id":"cHs1JYlKRSkv"},"source":["- Download data set"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_kWva0_RSkw","executionInfo":{"status":"ok","timestamp":1657241275864,"user_tz":-330,"elapsed":21850,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}},"outputId":"8202e4da-aab2-4a3f-b363-9543349432f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading Warwick dataset\n","Downloading data from https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip\n","180903936/180902609 [==============================] - 19s 0us/step\n","180912128/180902609 [==============================] - 19s 0us/step\n"]}],"source":["from pathlib import Path\n","home = str(Path.home())\n","data_folder = os.path.join(home, '/Users/aimachine/Documents/DeepLearningDatasets/Warwick QU Dataset (Released 2016_07_08)')\n","\n","if not os.path.exists(data_folder):\n","    print('Downloading Warwick dataset')\n","    from tensorflow.keras.utils import get_file \n","    dataset = get_file(\n","          fname=os.path.basename(URL),\n","          origin=URL, \n","          extract=True)\n","else:\n","    print('Warwick dataset found at {}'.format(data_folder) )\n","    print('Not downloading...')"]},{"cell_type":"markdown","metadata":{"id":"XGEnPHHYRSkx"},"source":["- Read image files and masks"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fISfm9ARSkx","executionInfo":{"status":"ok","timestamp":1657241534870,"user_tz":-330,"elapsed":1073,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}},"outputId":"104b4f80-df22-420b-f342-7387a827e4e6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":12}],"source":["fns_images = sort_human(glob.glob(os.path.join(data_folder, 'train_*.bmp')))\n","fns_masks  = sort_human(glob.glob(os.path.join(data_folder, 'train_*_anno.bmp')))\n","# remove _anno.bmp from path_images\n","fns_images = sort_human(list(set(fns_images) - set(fns_masks)))\n","fns_images[:10]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mX5iEr8CRSky","executionInfo":{"status":"ok","timestamp":1657241353679,"user_tz":-330,"elapsed":756,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}},"outputId":"74da028b-989a-4d51-81a6-906b86fcb185"},"outputs":[{"output_type":"stream","name":"stdout","text":["(0,)\n","0\n"]}],"source":["from skimage import transform\n","\n","images=[]\n","for fn in fns_images:\n","    image = import_image(fn, scale=True, verbose=False)\n","    image = transform.resize(image, (HEIGHT, WIDTH), mode='constant')\n","    #print(fn, image.shape)\n","    images.append(image)\n","images = np.array(images)\n","#print(images.shape, images.min(), images.max())\n","\n","masks=[]\n","for fn in fns_masks:\n","    basename = os.path.splitext(os.path.basename(fn))[0].split('_anno')[0]\n","    image = import_image(fn, verbose=False)\n","    image = transform.resize(image, (HEIGHT, WIDTH), order=0, mode='constant')\n","    mask = np.array(image>0, np.uint8)\n","    mask = mask[..., np.newaxis]\n","    masks.append(mask)\n","    \n","masks = np.array(masks)\n","\n","print(masks.shape)\n","\n","print(len(np.unique(masks)))"]},{"cell_type":"code","source":["images.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-JqfxfOSH7-","executionInfo":{"status":"ok","timestamp":1657241381087,"user_tz":-330,"elapsed":456,"user":{"displayName":"kapoorlabsintern India","userId":"14906127815508473654"}},"outputId":"47e47024-a24a-4c72-fb12-e0b079ab80fa"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0,)"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"3rVp4BuxRSky"},"source":["- data sample patches "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4vu7p9acRSkz"},"outputs":[],"source":["def sample_2Dtiles(image, annotation, tile_shape=(32,32), samples=10):\n","    sample_im=[]\n","    sample_mask=[]\n","    for i in range(samples):\n","        x = np.random.randint(0,image.shape[0]-tile_shape[0]-1)\n","        y = np.random.randint(0,image.shape[1]-tile_shape[1]-1)\n","        sample_im.append(   image[x:x+tile_shape[0],y:y+tile_shape[1]])\n","        sample_mask.append( annotation[x:x+tile_shape[0],y:y+tile_shape[1]])\n","    return np.array(sample_im), np.array(sample_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXFsjDWqRSkz","outputId":"586c7a24-8cd5-4901-ec01-a8f780ed8d41"},"outputs":[{"name":"stdout","output_type":"stream","text":["(850, 128, 128, 3) (850, 128, 128, 1)\n"]}],"source":["X = []\n","Y = []\n","for im, mask in zip(images, masks):\n","    x,y = sample_2Dtiles(im, mask, tile_shape=(PATCH_HEIGHT, PATCH_WIDTH), samples=10)\n","    X.append(x)\n","    Y.append(y)\n","    #print(x.shape)\n","X = np.array(X)\n","X = X.reshape((X.shape[0]*X.shape[1], X.shape[2], X.shape[3], X.shape[4]))\n","Y = np.array(Y)\n","Y = Y.reshape((Y.shape[0]*Y.shape[1], Y.shape[2], Y.shape[3], Y.shape[4]))\n","print(X.shape, Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KulRYHhRSkz","outputId":"823e1b11-d57f-4b59-b99c-ac567a242287"},"outputs":[{"name":"stdout","output_type":"stream","text":["X training: (680, 128, 128, 3)\n","X validation: (170, 128, 128, 3)\n","Y training: (680, 128, 128, 1)\n","Y validation: (170, 128, 128, 1)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","x_validation, x_train, y_validation, y_train = train_test_split(X, Y, test_size=.8)\n","print('X training: {}'.format(x_train.shape))\n","print('X validation: {}'.format(x_validation.shape))\n","print('Y training: {}'.format(y_train.shape))\n","print('Y validation: {}'.format(y_validation.shape))"]},{"cell_type":"markdown","metadata":{"id":"cBD3AerxRSk0"},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DmlpQ-0RSk0"},"outputs":[],"source":["def UNet(n_input_channels, n_output_channels):\n","    from keras.layers import Input, Dropout, UpSampling2D, MaxPooling2D, BatchNormalization, Conv2D, Concatenate\n","    from keras.models import Model\n","\n","    inputs = Input((None, None, n_input_channels))\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = Concatenate(axis=-1)([conv4,up6])\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = Concatenate(axis=-1)([conv3,up7])\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = Concatenate(axis=-1)([conv2,up8])\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = BatchNormalization()(conv8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    conv8 = BatchNormalization()(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = Concatenate(axis=-1)([conv1,up9])\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = BatchNormalization()(conv9)\n","    conv10 = Conv2D(n_output_channels, 1, activation = 'sigmoid')(conv9)\n","    \n","    return Model(inputs = inputs, outputs = conv10)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIWUK2CiRSk1"},"outputs":[],"source":["def MSD(width, depth, n_input_channels=1, n_output_channels=1, drop_out=0.0, batch_norm=False):\n","    from keras.layers import Input, merge, Dropout, BatchNormalization, Conv2D, Concatenate\n","    from keras.models import Model\n","    \n","    def convolution(n_filters, dilation, inputs, drop_out, name=None):\n","        if len(inputs) > 1:\n","            i = Concatenate()(inputs)\n","        else:\n","            i = inputs[0]\n","        c = Conv2D(filters=n_filters, dilation_rate=(dilation, dilation),\n","                                        kernel_size=(3,3), strides=(1,1), padding='same', \n","                                        activation='relu', use_bias=True, name=name)(i)\n","        if batch_norm:\n","            c = BatchNormalization()(c)\n","            \n","        if drop_out:\n","            c = Dropout(rate=drop_out)(c)\n","            \n","        return c\n","\n","    input_image = Input(shape=(None, None, n_input_channels), name='input')\n","    \n","    if batch_norm:\n","        bn = BatchNormalization(name='batchnorm')(input_image)\n","        inputs_layer = [bn]\n","    else:\n","        inputs_layer = [input_image]\n","    \n","    all_inputs = inputs_layer.copy()\n","    for i in range(depth):\n","        outputs_layer = []\n","        for j in range(width): \n","            # dilation rate = 1-10 in alternating cycles\n","            s_ij = ((i*width + j) % 10) + 1\n","            name = 'layer_{}_stride_{}'.format(i, s_ij)\n","            outputs_filter = convolution(n_filters=1, dilation=s_ij, inputs=inputs_layer, drop_out=drop_out, name=name)\n","            outputs_layer.append(outputs_filter)\n","            all_inputs.append(outputs_filter)\n","        inputs_layer.extend( outputs_layer )\n","        \n","    c = Concatenate()(all_inputs)\n","    o = Conv2D(filters=n_output_channels, kernel_size=(1,1), padding='same', activation='sigmoid')(c)\n","    \n","    model = Model(inputs=input_image, outputs=o)\n","        \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8B-4Ia3kRSk1","outputId":"d8a9c9e8-29b7-4d79-e980-239e75b1707a"},"outputs":[{"name":"stdout","output_type":"stream","text":["UNet: 31,056,397 params\n","MSD:  30,736 params\n","UNet has 1,010 times as many params as MSD!\n"]}],"source":["model_unet = UNet(n_input_channels=3, n_output_channels=1)\n","print('UNet: {:,} params'.format(model_unet.count_params()))\n","\n","model_msd = MSD(n_input_channels=3, n_output_channels=1, \n","                width=2, depth=40, drop_out=0.25, batch_norm=True)\n","print('MSD:  {:,} params'.format(model_msd.count_params()))\n","\n","print('UNet has {:,} times as many params as MSD!'.format( int(model_unet.count_params()/model_msd.count_params())))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhzE0ZUpRSk1"},"outputs":[],"source":["#draw_model(model_unet)\n","#draw_model(model_msd)"]},{"cell_type":"markdown","metadata":{"id":"iyjGYX_eRSk2"},"source":["# Loss function\n","\n","We use the [Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) as a measure of similarity between the predicted binary mask and the ground truth mask. This is equivalent the [F1 score](https://en.wikipedia.org/wiki/F1_score) for binary classification. \n","\n","The loss is simply the negative of the dice coefficient."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynj39ulXRSk2"},"outputs":[],"source":["import keras.backend as K\n","smooth=1.0\n","def dice_coef(y_true, y_pred):\n","    print(y_true.shape, 'shape')\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"xYu0Q9xMRSk2"},"source":["# Train models"]},{"cell_type":"markdown","metadata":{"id":"5nm31L1LRSk2"},"source":["- define callback to plot progress"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RM4PxpCeRSk2"},"outputs":[],"source":["from IPython.display import clear_output\n","from keras.callbacks import Callback\n","class PlotLearning(Callback):\n","\n","    def on_train_begin(self, logs={}):\n","        self.i = 0\n","        self.x = []\n","        self.loss = []\n","        self.val_loss = []\n","        self.acc = []\n","        self.val_acc = []\n","        self.fig = plt.figure()\n","        \n","        self.logs = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        \n","        self.logs.append(logs)\n","        self.x.append(self.i)\n","        self.loss.append(logs.get('loss'))\n","        self.acc.append(logs.get('dice_coef'))\n","        \n","        self.val_loss.append(logs.get('val_loss'))        \n","        self.val_acc.append(logs.get('val_dice_coef'))\n","        \n","        self.i += 1\n","        f, ax = plt.subplots(1, 2, figsize=(12,4), sharex=True)\n","        ax = ax.flatten()\n","        clear_output(wait=True)\n","        \n","        ax[0].plot(self.x, self.loss, label=\"loss\", lw=2)\n","        ax[0].plot(self.x, self.val_loss, label=\"val loss\")\n","        #ax[0].set_ylim(bottom=0.)\n","        ax[0].legend()\n","        ax[0].grid(True)\n","        \n","        ax[1].plot(self.x, self.acc, label=\"Dice coef\", lw=2)\n","        ax[1].plot(self.x, self.val_acc, label=\"val Dice coef\")\n","        #ax[1].set_ylim(bottom=0.)\n","        ax[1].legend()\n","        ax[1].grid(True)\n","        \n","        plt.show();\n","        \n","plotLoss = PlotLearning()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_n71jlrRSk3"},"outputs":[],"source":["batchsize = 8\n","epochs = 40\n","reload = False"]},{"cell_type":"markdown","metadata":{"id":"LQUBvW8wRSk3"},"source":["- Train UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NDV6R6ERSk3","outputId":"f3cfa35e-6ad4-4158-97d2-de74ac07bbf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(?, ?, ?, ?) shape\n","(?, ?, ?, ?) shape\n","Train on 680 samples, validate on 170 samples\n","Epoch 1/40\n","256/680 [==========>...................] - ETA: 10:03 - loss: -0.6428 - dice_coef: 0.6428"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["%%time\n","model_unet.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n","\n","history_unet = model_unet.fit(x_train, y_train, batch_size=batchsize, epochs=epochs, \n","                    verbose=1, shuffle=True, \n","                    validation_data=(x_validation, y_validation),\n","                    callbacks=[plotLoss])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Qlh3KHfkRSk3"},"source":["- Train MSD"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KsykKQfRSk4"},"outputs":[],"source":["%%time\n","model_msd.compile(optimizer='adam', loss=dice_coef_loss, metrics=[dice_coef])\n","\n","history_msd = model_msd.fit(x_train, y_train, batch_size=batchsize, epochs=epochs, \n","                    verbose=1, shuffle=True, \n","                    validation_data=(x_validation, y_validation),\n","                    callbacks=[plotLoss])\n"]},{"cell_type":"markdown","metadata":{"id":"xxGF7WRBRSk4"},"source":["# Predict"]},{"cell_type":"markdown","metadata":{"id":"3vJIMuFkRSk4"},"source":["- some utility function to predict sample and plot predictions as overlays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJirplruRSk4"},"outputs":[],"source":["def predict(model, num_samples=10, indices=None):\n","    import time\n","    tic = time.time()\n","    if indices is not None:\n","        samples_ind = indices\n","    else:\n","        samples_ind = np.random.randint(0, len(images), num_samples)\n","    \n","    sample_images = images[samples_ind]\n","    sample_masks = masks[samples_ind]\n","    predictions = model.predict(sample_images, batch_size=4)\n","    toc = time.time()\n","    print('Time per image = {:.4f} sec'.format((toc-tic) / num_samples))\n","    return sample_images, sample_masks, predictions, samples_ind\n","\n","def images_overlay(im1, im2, threshold=1e-2, title=None, alpha=0.25, cmap='Reds_r', ax=None, figsize=(5,5)):\n","    \n","    if ax is None:\n","        fig, ax = plt.subplots(1,1,figsize=figsize)\n","        \n","    im1 = np.squeeze(im1)\n","    im2 = np.squeeze(im2)\n","    \n","    ax.imshow(im1)\n","\n","    mask = np.ma.masked_less(im2, threshold)\n","    ax.contourf(mask >  threshold, alpha=alpha, cmap=cmap)\n","    ax.contour(im2, levels=[threshold], alpha=1.0, cmap=cmap)\n","    \n","    ax.axis('off')\n","    \n","    if title is not None:\n","        ax.set_title(title, fontsize=14)\n","        \n","def plot_prediction(x, y, y_pred_unet, y_pred_msd, sample):\n","    \n","    if sample >= len(y_pred_unet):\n","        raise ValueError('sample {} does not exist, max = {}'.format(sample, len(y_pred)-1))\n","    \n","    fig, ax = plt.subplots(1,3,figsize=(10,5))\n","    images_overlay(x[sample], y_pred_unet[sample], ax=ax[0], title='prediction UNet')\n","    images_overlay(x[sample], y_pred_msd[sample],  ax=ax[1], title='prediction MSD')\n","    images_overlay(x[sample], y[sample], ax=ax[2], title='annotation')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brQpbUjKRSk4"},"outputs":[],"source":["%%time\n","num_samples = 10\n","x, y, y_pred_unet, indices = predict(model_unet, num_samples=num_samples)\n","x, y, y_pred_msd, _        = predict(model_msd, indices=indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XprHbBprRSk5"},"outputs":[],"source":["_ = [plot_prediction(x, y, y_pred_unet, y_pred_msd, sample=i) for i in range(num_samples)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TriitpX9RSk5"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxpR2shERSk5"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRl38b5qRSk6"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b43mKb5mRSk6"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u_1cP86RSk6"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_Yd9RzNRSk6"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Segmentation_WarwickQU-mine.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}